{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "import os\n",
        "import random\n",
        "from typing import List\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "!pip install gcsfs\n"
      ],
      "metadata": {
        "id": "ZoEZdW92WaBF",
        "outputId": "cd55e2c1-b841-4426-dde8-946a46a1aba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "id": "ZoEZdW92WaBF",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (3.12.15)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: fsspec==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2025.3.0)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from gcsfs) (1.2.2)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.19.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.20.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (4.14.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.26.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gcsfs\n",
        "\n",
        "# Step 2: Authenticate to access Google Cloud Storage\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Step 3: Use gcsfs to interact with your bucket\n",
        "import gcsfs\n",
        "\n",
        "# Replace with your actual project ID if needed\n",
        "fs = gcsfs.GCSFileSystem()\n",
        "\n",
        "# Path to the training embeddings folder\n",
        "embedding_base_path = 'bracs-dataset-bucket/patch-embeddings/test'\n",
        "\n",
        "# Step 4: List WSI folders\n",
        "wsi_folders = fs.ls(embedding_base_path)\n",
        "\n",
        "# Only keep directories (some may include .pt files directly)\n",
        "wsi_dirs = [path for path in wsi_folders]\n",
        "\n",
        "print(f\"âœ… Number of WSI folders: {len(wsi_dirs)}\\n\")\n",
        "\n",
        "# Print first few folder names\n",
        "print(\"ðŸ“‚ Sample WSI Folders:\")\n",
        "for folder in wsi_dirs[:10]:\n",
        "    print(\"-\", folder)\n"
      ],
      "metadata": {
        "id": "d_ap6wCXWfxt",
        "outputId": "960c7dbd-3133-417e-f596-efee66203682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "d_ap6wCXWfxt",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Number of WSI folders: 63\n",
            "\n",
            "ðŸ“‚ Sample WSI Folders:\n",
            "- bracs-dataset-bucket/patch-embeddings/test/BRACS_1003691_embeddings.pt\n",
            "- bracs-dataset-bucket/patch-embeddings/test/BRACS_1003694_embeddings.pt\n",
            "- bracs-dataset-bucket/patch-embeddings/test/BRACS_1228_embeddings.pt\n",
            "- bracs-dataset-bucket/patch-embeddings/test/BRACS_1283_embeddings.pt\n",
            "- bracs-dataset-bucket/patch-embeddings/test/BRACS_1330_embeddings.pt\n",
            "- bracs-dataset-bucket/patch-embeddings/test/BRACS_1334_embeddings.pt\n",
            "- bracs-dataset-bucket/patch-embeddings/test/BRACS_1412_embeddings.pt\n",
            "- bracs-dataset-bucket/patch-embeddings/test/BRACS_1416_embeddings.pt\n",
            "- bracs-dataset-bucket/patch-embeddings/test/BRACS_1473_embeddings.pt\n",
            "- bracs-dataset-bucket/patch-embeddings/test/BRACS_1474_embeddings.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SeparableLITEScorer(nn.Module):\n",
        "    def __init__(self, max_query_patches=256, max_doc_patches=256, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.max_query_patches = max_query_patches\n",
        "        self.max_doc_patches = max_doc_patches\n",
        "\n",
        "        # Row-wise MLP over doc dimension\n",
        "        self.row_mlp = nn.Sequential(\n",
        "            nn.LayerNorm(max_doc_patches),\n",
        "            nn.Linear(max_doc_patches, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, max_doc_patches)\n",
        "        )\n",
        "\n",
        "        # Column-wise MLP over query dimension\n",
        "        self.col_mlp = nn.Sequential(\n",
        "            nn.LayerNorm(max_query_patches),\n",
        "            nn.Linear(max_query_patches, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, max_query_patches)\n",
        "        )\n",
        "\n",
        "        # Final projection to scalar\n",
        "        self.final_proj = nn.Linear(max_query_patches * max_doc_patches, 1)\n",
        "\n",
        "    def forward(self, S, q_mask, d_mask):\n",
        "        S_prime = self.row_mlp(S)                              # shape: [m, n]\n",
        "        S_double_prime = self.col_mlp(S_prime.T).T             # shape: [m, n]\n",
        "        flat = S_double_prime.reshape(1, -1)                   # shape: [1, m*n]\n",
        "        score = self.final_proj(flat)                          # shape: [1, 1]\n",
        "        return score.squeeze()\n",
        "import torch\n",
        "\n",
        "def prepare_patches(embeds, max_len=256):\n",
        "    \"\"\"\n",
        "    Truncates or pads the patch embeddings to size (max_len, D).\n",
        "    \"\"\"\n",
        "    L, D = embeds.shape\n",
        "    if L > max_len:\n",
        "        return embeds[:max_len]\n",
        "    else:\n",
        "        pad_len = max_len - L\n",
        "        pad_tensor = torch.zeros((pad_len, D), device=embeds.device)\n",
        "        return torch.cat([embeds, pad_tensor], dim=0)\n",
        "\n",
        "def prepare_mask(length, max_len=256):\n",
        "    \"\"\"\n",
        "    Returns a binary mask of shape (max_len,) with 1s for valid tokens.\n",
        "    \"\"\"\n",
        "    mask = torch.zeros((max_len,), dtype=torch.bool)\n",
        "    mask[:min(length, max_len)] = 1\n",
        "    return mask\n"
      ],
      "metadata": {
        "id": "d7_bc1AaW_40"
      },
      "id": "d7_bc1AaW_40",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download model from GCS manually first (if not already)\n",
        "!gsutil cp gs://bracs-dataset-bucket/checkpoints/scorer_epoch50.pt lite_scorer.pt\n",
        "import torch\n",
        "\n",
        "# Re-declare model class (SeparableLITEScorer) here as before\n",
        "model = SeparableLITEScorer()\n",
        "model.load_state_dict(torch.load(\"lite_scorer.pt\", map_location=torch.device(\"cpu\")))\n",
        "model.eval()\n",
        "print(\"âœ… Model loaded successfully.\")"
      ],
      "metadata": {
        "id": "0pFjVdiVWuqW",
        "outputId": "8638bfa1-1529-493a-a162-5f7b4eb96382",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0pFjVdiVWuqW",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://bracs-dataset-bucket/checkpoints/scorer_epoch50.pt...\n",
            "- [1 files][779.5 KiB/779.5 KiB]                                                \n",
            "Operation completed over 1 objects/779.5 KiB.                                    \n",
            "âœ… Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "xls = pd.ExcelFile(\"BRACS_BRACS.xlsx\")\n",
        "df_info = pd.read_excel(xls, \"WSI_Information\")\n",
        "\n",
        "# Build a lookup: WSI_ID â†’ global label index (0 to 6)\n",
        "lesions = ['N', 'PB', 'UDH', 'FEA', 'ADH', 'DCIS', 'IC']\n",
        "label2idx = {label: i for i, label in enumerate(lesions)}\n",
        "global_labels = {\n",
        "    row['WSI Filename']: label2idx[row['WSI label']]\n",
        "    for _, row in df_info.iterrows()\n",
        "    if row['WSI label'] in label2idx\n",
        "}\n"
      ],
      "metadata": {
        "id": "nsc3uR9EXGGL"
      },
      "id": "nsc3uR9EXGGL",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gcsfs\n",
        "import torch\n",
        "\n",
        "fs = gcsfs.GCSFileSystem()\n",
        "\n",
        "test_embedding_path = \"bracs-dataset-bucket/patch-embeddings/test\"\n",
        "test_slide_paths = []\n",
        "\n",
        "for f in fs.find(test_embedding_path):\n",
        "    if f.endswith(\"_embeddings.pt\"):\n",
        "        test_slide_paths.append(f)\n",
        "\n",
        "print(f\"âœ… Found {len(test_slide_paths)} test WSIs.\")"
      ],
      "metadata": {
        "id": "9NW-J1naYYS3",
        "outputId": "3dfc124a-3b54-4dff-b75c-191116b34026",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9NW-J1naYYS3",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Found 63 test WSIs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_embedding_from_gcs(path):\n",
        "    with fs.open(path, 'rb') as f:\n",
        "        data = torch.load(f, map_location='cpu')\n",
        "    return data\n",
        "\n",
        "def get_global_label_vector(slide_id):\n",
        "    if slide_id in global_labels:\n",
        "        label_index = global_labels[slide_id]\n",
        "        vec = torch.zeros(7)\n",
        "        vec[label_index] = 1.0\n",
        "        return vec\n",
        "    else:\n",
        "        print(f\"Warning: No global label found for slide {slide_id}.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "oAx8GGcJYbGP"
      },
      "id": "oAx8GGcJYbGP",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = {}\n",
        "\n",
        "for path in test_slide_paths:\n",
        "    slide_id = path.split(\"/\")[-1].split(\"_embeddings.pt\")[0]\n",
        "    label_vec = get_global_label_vector(slide_id)\n",
        "\n",
        "    if label_vec is None:\n",
        "        continue\n",
        "\n",
        "    emb = load_embedding_from_gcs(path)\n",
        "    mask = torch.ones(len(emb))  # all valid\n",
        "    test_data[slide_id] = {\n",
        "        \"emb\": emb,\n",
        "        \"mask\": mask,\n",
        "        \"label\": label_vec\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "print(f\"âœ… Valid test WSIs with labels: {len(test_data)}\")"
      ],
      "metadata": {
        "id": "R_JrksgaYk2i",
        "outputId": "59224664-6f87-4c02-a3d6-3ea381e517ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "R_JrksgaYk2i",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Valid test WSIs with labels: 63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_3NTTW52cAa8"
      },
      "id": "_3NTTW52cAa8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def prepare_patches(embeds, max_len=256):\n",
        "    \"\"\"\n",
        "    Truncate or pad the patch embeddings to size (max_len, D)\n",
        "    \"\"\"\n",
        "    L, D = embeds.shape\n",
        "    if L > max_len:\n",
        "        return embeds[:max_len]\n",
        "    else:\n",
        "        pad_len = max_len - L\n",
        "        pad_tensor = torch.zeros((pad_len, D), device=embeds.device)\n",
        "        return torch.cat([embeds, pad_tensor], dim=0)\n",
        "\n",
        "def prepare_mask(length, max_len=256):\n",
        "    \"\"\"\n",
        "    Binary mask of shape (max_len,) indicating valid patches.\n",
        "    \"\"\"\n",
        "    mask = torch.zeros((max_len,), dtype=torch.bool)\n",
        "    mask[:min(length, max_len)] = 1\n",
        "    return mask\n",
        "\n",
        "def get_similarity(q_emb, d_emb, scorer):\n",
        "    device = next(scorer.parameters()).device\n",
        "\n",
        "    q = F.normalize(q_emb, dim=-1).to(device)\n",
        "    d = F.normalize(d_emb, dim=-1).to(device)\n",
        "\n",
        "    q = prepare_patches(q, max_len=256)\n",
        "    d = prepare_patches(d, max_len=256)\n",
        "\n",
        "    q_mask = prepare_mask(q_emb.shape[0], max_len=256).to(device)\n",
        "    d_mask = prepare_mask(d_emb.shape[0], max_len=256).to(device)\n",
        "\n",
        "    S = torch.matmul(q, d.T)  # [256, 256]\n",
        "    score = scorer(S, q_mask, d_mask)\n",
        "\n",
        "    return torch.sigmoid(score).item()\n",
        "\n",
        "\n",
        "def evaluate_top_k(test_data, model, K=5):\n",
        "    correct_at_1 = 0\n",
        "    correct_at_k = 0\n",
        "    total = 0\n",
        "\n",
        "    slide_ids = list(test_data.keys())\n",
        "\n",
        "    for i, q_id in enumerate(slide_ids):\n",
        "        q_data = test_data[q_id]\n",
        "        sims = []\n",
        "\n",
        "        for j, d_id in enumerate(slide_ids):\n",
        "            if q_id == d_id:\n",
        "                continue\n",
        "\n",
        "            sim = get_similarity(q_data[\"emb\"], test_data[d_id][\"emb\"], model)\n",
        "            sims.append((d_id, sim))\n",
        "\n",
        "        # sort by similarity\n",
        "        sims.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_k = [sid for sid, _ in sims[:K]]\n",
        "\n",
        "        true_label = torch.argmax(q_data[\"label\"]).item()\n",
        "\n",
        "        top_labels = [torch.argmax(test_data[sid][\"label\"]).item() for sid in top_k]\n",
        "\n",
        "        correct_at_1 += (top_labels[0] == true_label)\n",
        "        correct_at_k += (true_label in top_labels)\n",
        "        total += 1\n",
        "\n",
        "    top1_acc = correct_at_1 / total\n",
        "    topk_acc = correct_at_k / total\n",
        "\n",
        "    print(f\"âœ… Top-1 Accuracy: {top1_acc:.4f}\")\n",
        "    print(f\"âœ… Top-{K} Accuracy: {topk_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "LtXfXn83Ywzl"
      },
      "id": "LtXfXn83Ywzl",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "test_data = {sid: info for sid, info in test_data.items() if info[\"emb\"].shape[0] >= 230}\n",
        "len(test_data)\n"
      ],
      "metadata": {
        "id": "0WF6y9Omm9Jh",
        "outputId": "7e88fd99-2a0d-48b9-d3c6-3789864765f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0WF6y9Omm9Jh",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_top_k(test_data, model, K=5)"
      ],
      "metadata": {
        "id": "Y2DKhYZaY_Hs",
        "outputId": "c27d0f9a-22a1-4f0e-dfb9-f97fb7d8176c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Y2DKhYZaY_Hs",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Top-1 Accuracy: 0.1220\n",
            "âœ… Top-5 Accuracy: 0.4878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_top_k(test_data, model, K=3)"
      ],
      "metadata": {
        "id": "oeIP9CwGiZef",
        "outputId": "88eaae16-833a-4056-921b-607659d97a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oeIP9CwGiZef",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Top-1 Accuracy: 0.2222\n",
            "âœ… Top-3 Accuracy: 0.5556\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}